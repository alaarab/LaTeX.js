(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{438:function(e,t,a){"use strict";a.r(t);var s=a(55),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"limitations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#limitations"}},[e._v("#")]),e._v(" Limitations")]),e._v(" "),a("ul",[a("li",[e._v("I don't create an intermediate AST yet, so TeX's conditional expressions are impossible")]),e._v(" "),a("li",[e._v("deprecated macros, or macros that are not supposed to be used in LaTeX, won't even exist in LaTeX.js.\nExamples include: "),a("code",[e._v("eqnarray")]),e._v(", the old LaTeX 2.09 font macros "),a("code",[e._v("\\it")]),e._v(", "),a("code",[e._v("\\sl")]),e._v(", etc. Also missing are most of the plainTeX macros.\nSee also "),a("a",{attrs:{href:"ftp://ftp.dante.de/tex-archive/info/l2tabu/english/l2tabuen.pdf"}},[a("code",[e._v("l2tabuen.pdf")])]),e._v(".")]),e._v(" "),a("li",[e._v("incorrect but legal markup in LaTeX won't produce the same result in LaTeX.js - like when using "),a("code",[e._v("\\raggedleft")]),e._v(" in the\nmiddle of a paragraph; but the LaTeX.js result should be intuitively correct.")]),e._v(" "),a("li",[e._v("because of the limitations when parsing TeX as a context-free grammar (see "),a("a",{attrs:{href:"#parsing-tex"}},[e._v("below")]),e._v("), native LaTeX packages\ncannot be parsed and loaded. Instead, the macros those packages (and documentclasses) provide have to be implemented in\nJavaScript.")]),e._v(" "),a("li",[e._v("every macro in LaTeX.js has to return a document (fragment) node, so incomplete snippets of LaTeX are currently unsupported; this\nwill be fixed by an intermediate AST.")])]),e._v(" "),a("h2",{attrs:{id:"limitations-of-latex-js-due-to-html-and-css"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#limitations-of-latex-js-due-to-html-and-css"}},[e._v("#")]),e._v(" Limitations of LaTeX.js due to HTML and CSS")]),e._v(" "),a("p",[e._v("There are some limitations that could theoretically be fixed with (a lot) more effort:")]),e._v(" "),a("ul",[a("li",[e._v("TeX boxes have a height and a depth, the depth being 0 if the box doesn't contain text that needs it. CSS boxes don't know\nabout depth, they only have a height. HTML text in a box does have a baseline, but it "),a("em",[e._v("always")]),e._v(" adds the space under the baseline.\nThis causes little visual differences compared to LaTeX.")])]),e._v(" "),a("p",[e._v("The following features in LaTeX just cannot be translated to HTML, not even when using JavaScript:")]),e._v(" "),a("ul",[a("li",[e._v("TeX removes any whitespace from the beginning and end of a line, even consecutive ones that would be printed in the middle\nof a line, like "),a("code",[e._v("\\")]),e._v(" or "),a("code",[e._v("~")]),e._v(" or ^^0020. This is not possible in HTML (yet - maybe it will be with CSS4).")]),e._v(" "),a("li",[e._v("horizontal glue, like "),a("code",[e._v("\\hfill")]),e._v(" in a paragraph of text, is not possible")]),e._v(" "),a("li",[e._v("vertical glue makes no sense in HTML, and is impossible to emulate, except in boxes with fixed height")]),e._v(" "),a("li",[a("code",[e._v("\\vspace{}")]),e._v(" with a negative value in horizontal mode, i.e. in the middle of a paragraph of text, is not possible\n(but this feature is useless anyway)")])]),e._v(" "),a("p",[e._v("And the concept of pages does not really apply to HTML, so any macro related to pagebreaks will be ignored. One\ncould say that splitting a HTML file into multiple files is like a pagebreak, but then, still, it would be much\neasier to handle: just choose a break before a new section or paragraph. There is no absolute space limitation\nlike on a real page.")]),e._v(" "),a("h2",{attrs:{id:"limitations-when-parsing-tex-as-a-context-free-grammar"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#limitations-when-parsing-tex-as-a-context-free-grammar"}},[e._v("#")]),e._v(" "),a("a",{attrs:{name:"parsing-tex"}}),e._v(" Limitations when parsing TeX as a context-free grammar")]),e._v(" "),a("p",[e._v("This is a PEG parser, which means it interprets LaTeX as a context-free language. However, TeX (and therefore LaTeX) is\nTuring complete, so TeX can only really be parsed by a complete Turing machine. It is not possible to parse the full\nTeX language with a static parser. See\n"),a("a",{attrs:{href:"https://tex.stackexchange.com/questions/4201/is-there-a-bnf-grammar-of-the-tex-language",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),a("OutboundLink")],1),e._v(" for some interesting\nexamples.")]),e._v(" "),a("p",[e._v("It is even undecidable whether a TeX program has a parse tree. There has been done some research\non the problem of parsing TeX, see "),a("a",{attrs:{href:"http://www.mathematik.uni-marburg.de/~seba/publications/sle10.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),a("OutboundLink")],1),e._v(".")]),e._v(" "),a("p",[e._v("To quote the four problems of TeX:")]),e._v(" "),a("ul",[a("li",[a("p",[e._v("Since TeX has dynamic scoping, it is not possible to determine statically\nwheather "),a("code",[e._v("a")]),e._v(" is an argument to "),a("code",[e._v("\\app")]),e._v(" in "),a("code",[e._v("\\app a")]),e._v(" or just another letter. It depends on the definition of "),a("code",[e._v("\\app")]),e._v(" at\nruntime.")])]),e._v(" "),a("li",[a("p",[e._v("Macros can be passed as arguments to other macros, further complicating this problem. E.g.:")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\def")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\app")]),e._v(" #1 #2 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("#1 #2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\def")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\id")]),e._v(" #1 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("#1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\app")]),e._v(" a b\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\app")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\id")]),e._v(" c\n")])])]),a("p",[e._v("Thus, targets of macro calls can in general not be determined statically.")])]),e._v(" "),a("li",[a("p",[e._v("TeX has a lexical macro system, which means macro bodies do not have to be syntactically correct pieces\nof TeX code. Also, macros can expand to new macro definitions.")])]),e._v(" "),a("li",[a("p",[e._v("Tex allows custom macro call syntax. Basically, any syntax could be changed.")])])]),e._v(" "),a("p",[e._v("I therefore take a slightly different approach:")]),e._v(" "),a("ul",[a("li",[a("p",[e._v("First, I don't care about TeX, but only LaTeX, and most LaTeX documents do not use TeX syntax, or "),a("code",[e._v("\\def")]),e._v(" in\nparticular. Therefore, this parser assumes standard LaTeX syntax and catcodes.")])]),e._v(" "),a("li",[a("p",[e._v("Second, for now there is no way of defining macros, only expanding macros is supported. So if a new\nLaTeX macro is needed, reimplement it in JavaScript directly, thus circumventing the problem altogether.")])])]),e._v(" "),a("h3",{attrs:{id:"expansion-and-execution"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#expansion-and-execution"}},[e._v("#")]),e._v(" Expansion and Execution")]),e._v(" "),a("p",[e._v("Additionally, this parser does not implement TeX's distinction of expansion and\nexecution. I am not yet sure if I need to implement it at all. Right now, there is only one phase that takes a macro\nand returns an HTML fragment.")]),e._v(" "),a("p",[e._v("Skipped spaces and macros that expand to a macro taking a parameter further down in the input provide a good\nillustration of why TeX makes this distinction. Consider the commands")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\def")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\a")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\penalty")]),e._v("200"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n"),a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\a")]),e._v(" 0\n")])])]),a("p",[e._v("This is not equivalent to")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\penalty")]),e._v("200 0\n")])])]),a("p",[e._v("which would place a penalty of 200, and typeset the digit 0. Instead, it expands to")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\penalty")]),e._v("2000\n")])])]),a("p",[e._v("because the space after \\a is skipped in the input processor. Later stages of processing then receive the sequence")]),e._v(" "),a("div",{staticClass:"language-tex extra-class"},[a("pre",{pre:!0,attrs:{class:"language-tex"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function selector"}},[e._v("\\a")]),e._v("0\n")])])]),a("p",[e._v("However, LaTeX documents themselves usually don't rely on or need this feature--that is, until I'm convinced otherwise.")]),e._v(" "),a("p",[e._v("This also means that you cannot use "),a("code",[e._v("\\vs^^+ip")]),e._v(" to have LaTeX.js interpret it as "),a("code",[e._v("\\vskip")]),e._v(". Again, this is a feature\nthat most people will probably never need.")])])}),[],!1,null,null,null);t.default=n.exports}}]);